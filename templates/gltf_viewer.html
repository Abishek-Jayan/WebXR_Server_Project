<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Model Viewer - Sprite</title>
    <script type="importmap">
    {
    "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.179.0/build/three.module.js",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.179.0/examples/jsm/"
    }
    }
    </script>
    <script src="https://rawgit.com/kawanet/msgpack-lite/master/dist/msgpack.min.js"></script>

</head>

<body>
    <script type="module">
        const width = window.innerWidth;
        const height = window.innerHeight;
        import { VRButton } from "three/addons/webxr/VRButton.js";
        import { XRControllerModelFactory } from "three/addons/webxr/XRControllerModelFactory.js";
        import * as THREE from "three";
        const pc = new RTCPeerConnection({
            iceServers: [{ urls: "stun:stun.l.google.com:19302" }]
            });
        const video = document.createElement("video");
        video.autoplay = true;
        video.playsInline = true;
        video.muted = true;  // WebRTC requires muted autoplay sometimes
        const videoTexture = new THREE.VideoTexture(video);
        

        // Initialize renderer with optimal settings
        const renderer = new THREE.WebGLRenderer({
            antialias: true,
            powerPreference: "high-performance",
        });
        renderer.setSize(width, height);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 1.5));
        renderer.xr.enabled = true;
        renderer.autoClear = true; // Changed back to true to ensure proper clearing

        document.body.appendChild(renderer.domElement);
        document.body.appendChild(VRButton.createButton(renderer));

        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(110, window.innerWidth / window.innerHeight);
        let raycaster, controller1, controller2, controllerGrip1, controllerGrip2;
        let marker, floor, baseReferenceSpace, INTERSECTION;
        const tempMatrix = new THREE.Matrix4();


        const leftMaterial = new THREE.SpriteMaterial({map:videoTexture});
        const rightMaterial = new THREE.SpriteMaterial({map:videoTexture});
        const leftSprite = new THREE.Sprite(leftMaterial);
        const rightSprite = new THREE.Sprite(rightMaterial);

        leftSprite.position.set(-0.03, 0, -1); // Closer to camera
        leftSprite.scale.set(16, 9, 1);
        leftSprite.layers.set(0);
        camera.add(leftSprite); // Attach to camera


        rightSprite.position.set(0.03, 0, -1); // Closer to camera
        rightSprite.scale.set(16, 9, 1);
        rightSprite.layers.set(0);
        camera.add(rightSprite); // Attach to camera

        scene.add(camera); // Ensure camera is in the scene
        camera.layers.enable(1);
        camera.layers.enable(2);
        marker = new THREE.Mesh(
            new THREE.CircleGeometry(0.25, 32).rotateX(-Math.PI / 2),
            new THREE.MeshBasicMaterial({ color: 0x00ff00, side: THREE.DoubleSide , transparent: true, opacity: 1.0 })
        );
        marker.material.depthTest = false;
        marker.material.depthWrite = false;
        marker.renderOrder = 1000;
        scene.add(marker);

        floor = new THREE.Mesh(
            new THREE.PlaneGeometry(1000, 1000, 50,50).rotateX(-Math.PI / 2),
            new THREE.MeshBasicMaterial({ color: 0x000000,wireframe: true})
        );
        floor.material.depthTest = false;   // ignores depth buffer
        floor.renderOrder = 999;   
        scene.add(floor);

        raycaster = new THREE.Raycaster();
        const sendInterval = 1000 / 20; // 20 Hz
        let lastPosition = camera.position.clone();
        let lastQuaternion = camera.quaternion.clone();
        let lastSendTime = 0;

        
        function onSelectStart() { this.userData.isSelecting = true; }
    function onSelectEnd() {
    this.userData.isSelecting = false;
    if (INTERSECTION) {
        const offsetPosition = { x: -INTERSECTION.x, y: -INTERSECTION.y, z: -INTERSECTION.z, w: 1 };
        const offsetRotation = new THREE.Quaternion();
        const transform = new XRRigidTransform(offsetPosition, offsetRotation);
        const teleportSpaceOffset = baseReferenceSpace.getOffsetReferenceSpace(transform);
        renderer.xr.setReferenceSpace(teleportSpaceOffset);
        }
    }

        controller1 = renderer.xr.getController(0);
        controller1.addEventListener("selectstart", onSelectStart);
        controller1.addEventListener("selectend", onSelectEnd);
        scene.add(controller1);

        controller2 = renderer.xr.getController(1);
        controller2.addEventListener("selectstart", onSelectStart);
        controller2.addEventListener("selectend", onSelectEnd);
        scene.add(controller2);

        const controllerModelFactory = new XRControllerModelFactory();
        controllerGrip1 = renderer.xr.getControllerGrip(0);
        controllerGrip1.add(controllerModelFactory.createControllerModel(controllerGrip1));
        scene.add(controllerGrip1);

        controllerGrip2 = renderer.xr.getControllerGrip(1);
        controllerGrip2.add(controllerModelFactory.createControllerModel(controllerGrip2));
        scene.add(controllerGrip2);


        renderer.setAnimationLoop((timestamp, frame) => {


            INTERSECTION = undefined;
            if (controller1.userData.isSelecting) {
                tempMatrix.identity().extractRotation(controller1.matrixWorld);
                raycaster.ray.origin.setFromMatrixPosition(controller1.matrixWorld);
                raycaster.ray.direction.set(0, 0, -1).applyMatrix4(tempMatrix);
                const intersects = raycaster.intersectObjects([floor]);
                if (intersects.length > 0) INTERSECTION = intersects[0].point;
            } else if (controller2.userData.isSelecting) {
                tempMatrix.identity().extractRotation(controller2.matrixWorld);
                raycaster.ray.origin.setFromMatrixPosition(controller2.matrixWorld);
                raycaster.ray.direction.set(0, 0, -1).applyMatrix4(tempMatrix);
                const intersects = raycaster.intersectObjects([floor]);
                if (intersects.length > 0) INTERSECTION = intersects[0].point;
            }

            if (INTERSECTION) marker.position.copy(INTERSECTION);
            marker.visible = INTERSECTION !== undefined;


            renderer.render(scene, camera);
        });



        
        async function startWebRTC() {
            
            // Attach remote stream
            const capabilities = RTCRtpReceiver.getCapabilities('video');
            const h264Codecs = capabilities.codecs.filter(codec => codec.mimeType === 'video/H264');
            pc.addTransceiver("video").setCodecPreferences(h264Codecs);
            pc.ontrack = (event) => {
                console.log("ontrack fired:", event.track, "streams:", event.streams);
                video.srcObject = event.streams[0];
                video.play();
                video.onplaying = () => console.log("Video is playing");
                video.onpause = () => console.log("Video paused");
            
            };

            pc.onconnectionstatechange = () => console.log("PC state:", pc.connectionState);
            pc.oniceconnectionstatechange = () => console.log("ICE state:", pc.iceConnectionState);
            // Create data channel if needed for sending camera updates
            pc.onicecandidate = (event) => {
            if (event.candidate) {
                fetch("/candidate", {
                method: "POST",
                body: JSON.stringify({candidate: event.candidate.candidate,
                sdpMid: event.candidate.sdpMid,
                sdpMLineIndex: event.candidate.sdpMLineIndex}),
                headers: { "Content-Type": "application/json" },
                });
            }
            };
            const dc = pc.createDataChannel("camera");
            dc.onopen = () => console.log("Data channel open");

            // Send camera updates through data channel instead of socket.emit
            function sendCameraUpdate() {
                const posQuat = {
                    position: { x: camera.position.x, y: camera.position.y, z: camera.position.z },
                    quaternion: { w: camera.quaternion.w, x: camera.quaternion.x, y: camera.quaternion.y, z: camera.quaternion.z }
                };
                if (dc.readyState === "open") {
                    dc.send(JSON.stringify(posQuat));
                }
            }

            // Periodically send camera updates
            setInterval(sendCameraUpdate, 50); // 20 Hz

            // Create offer to backend
            const offer = await pc.createOffer({ offerToReceiveVideo: true });
            await pc.setLocalDescription(offer);

            // Send offer to backend
            const resp = await fetch("/offer", {
                method: "POST",
                body: JSON.stringify(pc.localDescription),
                headers: { "Content-Type": "application/json" },
            });
            const answer = await resp.json();
            await pc.setRemoteDescription(answer);
        }

        startWebRTC();




        renderer.xr.addEventListener('sessionstart', () => {
            console.log("VR session started");
            baseReferenceSpace = renderer.xr.getReferenceSpace();
        });
    </script>
</body>

</html>