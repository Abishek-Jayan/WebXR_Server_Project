<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Model Viewer - Sprite</title>
    <script type="importmap">
    {
    "imports": {
        "THREE": "https://cdn.jsdelivr.net/npm/three@0.179.0/build/three.module.js",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.179.0/examples/jsm/"
    }
    }
    </script>
    <script src="https://cdn.socket.io/4.8.1/socket.io.min.js"></script>

</head>

<body>
    <script type="module">
        const width = {{SCREEN_WIDTH}};
        const height = {{SCREEN_HEIGHT}};
        import { VRButton } from "three/addons/webxr/VRButton.js";
        import * as THREE from "THREE";
        const socket = io();


        // Initialize renderer with optimal settings
        const renderer = new THREE.WebGLRenderer({
            antialias: true,
            powerPreference: "high-performance",
            alpha: true
        });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 1.5));
        renderer.xr.enabled = true;
        renderer.autoClear = true; // Changed back to true to ensure proper clearing

        document.body.appendChild(renderer.domElement);
        document.body.appendChild(VRButton.createButton(renderer));

        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(110, window.innerWidth / window.innerHeight);

        

        socket.on('connect', () => {
            console.log("Connected to server");
            socket.emit('camera_data', JSON.stringify({
                position: { x: camera.position.x, y: camera.position.y, z: camera.position.z },
                quaternion: { w: camera.quaternion.w, x: camera.quaternion.x, y: camera.quaternion.y, z: camera.quaternion.z }
            }));
        });
        socket.on('disconnect', () => console.log("Disconnected from server"));
                
        // Create Sprites with DataTextures for left and right eyes
        const leftTexture = new THREE.Texture();
        leftTexture.minFilter = THREE.LinearFilter;
        leftTexture.magFilter = THREE.LinearFilter;
        const leftMaterial = new THREE.SpriteMaterial({ map: leftTexture });
        const leftSprite = new THREE.Sprite(leftMaterial);
        leftSprite.scale.set(16, 9, 1);
        leftSprite.position.set(-0.03, 0, -1); // Closer to camera
        leftSprite.layers.set(1);
        camera.add(leftSprite); // Attach to camera

        const rightTexture = new THREE.Texture();
        rightTexture.minFilter = THREE.LinearFilter;
        rightTexture.magFilter = THREE.LinearFilter;
        const rightMaterial = new THREE.SpriteMaterial({ map: rightTexture });
        const rightSprite = new THREE.Sprite(rightMaterial);
        rightSprite.scale.set(16, 9, 1);
        rightSprite.position.set(0.03, 0, -1); // Closer to camera
        rightSprite.layers.set(2);
        camera.add(rightSprite); // Attach to camera

        scene.add(camera); // Ensure camera is in the scene
        camera.layers.enable(1);
        camera.layers.enable(2);


        renderer.setAnimationLoop(() => {
            renderer.render(scene, camera);
        });

        socket.on('image_update', async (data) => {
            const start = performance.now();
            console.log("New Images Received");

            const leftImg = new Image();
            leftImg.src = "data:image/webp;base64," + data.left_image;
            await leftImg.decode();
            
            const rightImg = new Image();
            rightImg.src = "data:image/webp;base64," + data.right_image;
            await rightImg.decode();
            leftTexture.image = leftImg;
            leftTexture.needsUpdate = true;

            rightTexture.image = rightImg;
            rightTexture.needsUpdate = true;

            // Log pixel data for debugging
            console.log("Updated new images");
            const end = performance.now();
            console.log(`Image update processing time: ${(end - start).toFixed(2)} ms`);

        });

        let lastPosition = camera.position.clone();
        let lastQuaternion = camera.quaternion.clone();

        renderer.xr.addEventListener('sessionstart', () => {
            console.log("VR session started");
            setInterval(() => {
                if (renderer.xr.isPresenting) {
                    const start = performance.now();
                    const posChanged = !camera.position.equals(lastPosition);
                    const quatChanged = !camera.quaternion.equals(lastQuaternion);
                    if (posChanged || quatChanged) {
                        socket.emit('camera_data', JSON.stringify({
                            position: { x: camera.position.x, y: camera.position.y, z: camera.position.z },
                            quaternion: { w: camera.quaternion.w, x: camera.quaternion.x, y: camera.quaternion.y, z: camera.quaternion.z }
                        }));
                        lastPosition.copy(camera.position);
                        lastQuaternion.copy(camera.quaternion);
                        const end = performance.now();
                        console.log(`Camera data check/send time: ${(end - start).toFixed(2)} ms`);
                    }
                }
            }, 1000 / 20); // 20 Hz
        });
    </script>
</body>

</html>